Retrieval Augmented Generation:
WHY:
    - LLM stores their knowledge in parametric form. LLM doesnt work in recent data, private data and hallucination problems.
    - We can fine-tune a pre-trained model on a domain specific dataset, there are many techniques to train the LLM: Supervised: give labelled dataset (prompt and the desired output), unsupervised: give the dataset of the domai specific datasets.
    - We need to fine-tune each time the dataset changes or expands,  this is computationally costly, techincal expertise required.
    - In-context learning: core capability of LLM to solve a task purely by seeing examples in the prompt without updating its weights
    - instread of just examples, we can inject the knowledge in the prompt, this is RAG. 

How: 
    RAG = Info Retrieval + Text Generation
    - Indexing: Creating the external KB, so that it can be searched easily. Document Ingstion (Doc loaders) --> Text Chunking (Text splitters) --> Embedding (creating vectors) --> Storing vector + metadata in vectorDB. This VectorDB is the External KB
    - Retrieval: Taking the relevant docs/chunks from the KB. Find the most relevant chunks, k most relevant chunks to ans the user query.
    - Augmentation: Creating a prompt with query and context retrieved.
    - Generation of text using LLM

RAG can now used to ans on private data as we are giving it to the LLM. We can just update our KB so that that we can ans on the recent developnments. Hallucinations prob is also solved. Less complex and cheaper than fine-tuning LLMs

Tools: Python function or API that is packaged in a way the LLM can understand it and call it when needed.
Agent = LLM + Tools
Langchain has:
    - Built-in tools: frequently used tools, pre-built, requires minimal setup
    - Custom Tools: specific to your usecase, call your own API, you want to encapsulate business logic, want LLM to interact with your databse, product or app
        - @tool decorator 
        - A structured tool is a special type where the input to the tookl follows a structured schema, using a Pydantic model
        - BaseTool class: It is an abstract base class for all tools in LangChain. It defines the core structure and interface for any tool must follow. All other tool types (@tool, StructuredTool) are built on top of BaseTool
    
    -ToolKits: Collection of related tools that serve a common purpose, packaged together for convinience

    Tool Binding: registering a tool with a LLM, so that LLM knows what tool are available, it knows what each tool does, whats the input format(via schema)
    ToolCalling: process where an LLM decides that it needs to use a specific tool and generates a structured output with:
        - name of the tool
        - arguments to call it with
    LLM wont run the tool, it will handled by dev or langchain

    Tool Execution: where actually the Python function is run using using the input args that the LLM suggested during tool calling.

    AGENTS:
        ReAct: It is a design pattern used in AI agents for Reasoning + Acting. It allows an LLM to interleave internal reasoning with external actions(tools) in a structured multi-step process.
        It does Thought-->Action-->Observation in a loop until it gets a convinient ans.
            - Useful for:
                - Multi-step problems
                - Tool-Augmented tasks
                - Making the agent's reasoning trnsparent and auditable
        
        Agent and Agent Executor: AgentEX orchestrates the entire loop:
            - sends input and previous messages to the agent
            - gets the next action from agent
            - executs the tool with provided input
            - adds the tool's observation back in the history
            - loops again with updated history until agent says Final Answer

        agent = create_react_agent(
            llm = llm,
            tools = [search_tool],
            prompt = prompt
        )

        agent_executor = AgentExecutor(
            agent = agent,
            tools = [search_tool],
            verbose = True
        )